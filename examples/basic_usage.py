#!/usr/bin/env python3
"""AllFlowåŸºç¡€ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨AllFlowåº“è¿›è¡ŒFlow Matchingç®—æ³•çš„åŸºæœ¬æ“ä½œï¼Œ
åŒ…æ‹¬ç®—æ³•åˆå§‹åŒ–ã€è½¨è¿¹é‡‡æ ·ã€é€Ÿåº¦åœºè®¡ç®—å’ŒåŸºç¡€è®­ç»ƒæµç¨‹ã€‚

è¿è¡Œæ–¹å¼:
    python examples/basic_usage.py

Author: AllFlow Contributors
"""

import sys
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ src ç›®å½•æ·»åŠ åˆ° Python è§£é‡Šå™¨çš„æœç´¢è·¯å¾„ä¸­
sys.path.insert(0, str(Path(__file__).resolve().parent.parent / "src"))

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# å¯¼å…¥AllFlow
from allflow.algorithms.flow_matching import FlowMatching


def simple_model_example():
    """æ¼”ç¤ºåŸºç¡€Flow Matchingç®—æ³•çš„ä½¿ç”¨."""
    print("ğŸ¯ åŸºç¡€Flow Matchingç¤ºä¾‹")
    print("=" * 50)

    # 1. åˆ›å»ºFlow Matchingå®ä¾‹
    flow = FlowMatching(device="cpu")
    print(f"âœ… Flow Matchingåˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {flow.device}")

    # 2. åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 32
    dim = 64

    # æºåˆ†å¸ƒï¼šæ ‡å‡†é«˜æ–¯åˆ†å¸ƒ
    x_0 = torch.randn(batch_size, dim)

    # ç›®æ ‡åˆ†å¸ƒï¼šåç§»çš„é«˜æ–¯åˆ†å¸ƒ
    x_1 = torch.randn(batch_size, dim) * 0.5 + 2.0

    # éšæœºæ—¶é—´ç‚¹
    t = torch.rand(batch_size)

    print("âœ… æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ")
    print(f"   æºåˆ†å¸ƒå½¢çŠ¶: {x_0.shape}, å‡å€¼: {x_0.mean():.3f}")
    print(f"   ç›®æ ‡åˆ†å¸ƒå½¢çŠ¶: {x_1.shape}, å‡å€¼: {x_1.mean():.3f}")

    # 3. è½¨è¿¹é‡‡æ ·
    x_t = flow.sample_trajectory(x_0, x_1, t)
    print(f"âœ… è½¨è¿¹é‡‡æ ·å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {x_t.shape}")

    # 4. é€Ÿåº¦åœºè®¡ç®—
    velocity = flow.compute_vector_field(x_t, t, x_0=x_0, x_1=x_1)
    print(f"âœ… é€Ÿåº¦åœºè®¡ç®—å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {velocity.shape}")

    # 5. éªŒè¯æ•°å­¦æ­£ç¡®æ€§
    expected_velocity = x_1 - x_0
    error = torch.norm(velocity - expected_velocity)
    print(f"âœ… æ•°å­¦æ­£ç¡®æ€§éªŒè¯: è¯¯å·® = {error:.2e}")

    return flow, x_0, x_1, t


def training_example():
    """æ¼”ç¤ºFlow Matchingçš„è®­ç»ƒè¿‡ç¨‹."""
    print("\nğŸš€ Flow Matchingè®­ç»ƒç¤ºä¾‹")
    print("=" * 50)

    # 1. åˆ›å»ºFlow Matchingå’Œç®€å•ç¥ç»ç½‘ç»œ
    flow = FlowMatching(device="cpu")

    # ç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºä½œä¸ºé€Ÿåº¦åœºé¢„æµ‹å™¨
    class SimpleVelocityModel(nn.Module):
        def __init__(self, dim: int, time_embed_dim: int = 64):
            super().__init__()
            self.time_mlp = nn.Sequential(
                nn.Linear(1, time_embed_dim),
                nn.SiLU(),
                nn.Linear(time_embed_dim, time_embed_dim),
            )
            self.velocity_net = nn.Sequential(
                nn.Linear(dim + time_embed_dim, 256),
                nn.SiLU(),
                nn.Linear(256, 256),
                nn.SiLU(),
                nn.Linear(256, dim),
            )

        def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
            # æ—¶é—´åµŒå…¥
            t_embed = self.time_mlp(t.unsqueeze(-1))

            # æ‹¼æ¥ä½ç½®å’Œæ—¶é—´ä¿¡æ¯
            x_t_cat = torch.cat([x, t_embed], dim=-1)

            # é¢„æµ‹é€Ÿåº¦åœº
            return self.velocity_net(x_t_cat)

    dim = 32
    model = SimpleVelocityModel(dim)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    print(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # 2. è®­ç»ƒå¾ªç¯
    num_epochs = 50
    batch_size = 128
    losses = []

    print(f"ğŸ”„ å¼€å§‹è®­ç»ƒ ({num_epochs} epochs)...")

    for epoch in range(num_epochs):
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        x_0 = torch.randn(batch_size, dim)
        x_1 = torch.randn(batch_size, dim) * 0.8 + torch.tensor(
            [2.0, -1.0] + [0.0] * (dim - 2)
        )

        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        x_t, t, true_velocity = flow.prepare_training_data(x_0, x_1)
        predicted_velocity = model(x_t, t)
        loss = flow.compute_loss(x_0, x_1, t, predicted_velocity)

        # åå‘ä¼ æ’­
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        losses.append(loss.item())

        if epoch % 10 == 0 or epoch == num_epochs - 1:
            print(f"   Epoch {epoch:3d}: æŸå¤± = {loss.item():.6f}")

    print(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")

    # 3. ç”Ÿæˆé‡‡æ ·
    print("ğŸ¨ ç”Ÿæˆé‡‡æ ·...")

    model.eval()
    with torch.no_grad():
        # ä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒå¼€å§‹
        num_samples = 100
        x_init = torch.randn(num_samples, dim)

        # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆæ ·æœ¬
        generated = flow.generate_sample(x_init, model, num_steps=50, method="euler")

        print("âœ… ç”Ÿæˆå®Œæˆ")
        print(f"   åˆå§‹åˆ†å¸ƒå‡å€¼: {x_init.mean(dim=0)[:2].numpy()}")
        print(f"   ç”Ÿæˆåˆ†å¸ƒå‡å€¼: {generated.mean(dim=0)[:2].numpy()}")
        print("   ç›®æ ‡åˆ†å¸ƒå‡å€¼: [2.0, -1.0]")

    return model, losses


def visualization_example():
    """2Då¯è§†åŒ–ç¤ºä¾‹."""
    print("\nğŸ“Š 2Då¯è§†åŒ–ç¤ºä¾‹")
    print("=" * 50)

    try:
        # åˆ›å»º2D Flow Matching
        flow = FlowMatching(device="cpu")

        # ç”Ÿæˆ2Dæ•°æ®
        num_points = 500

        # æºåˆ†å¸ƒï¼šåœ†å½¢åˆ†å¸ƒ
        theta = torch.rand(num_points) * 2 * np.pi
        r = torch.randn(num_points) * 0.3 + 1.0
        x_0 = torch.stack([r * torch.cos(theta), r * torch.sin(theta)], dim=1)

        # ç›®æ ‡åˆ†å¸ƒï¼šå¿ƒå½¢åˆ†å¸ƒ
        t_heart = torch.rand(num_points) * 2 * np.pi
        x_heart = 16 * torch.sin(t_heart) ** 3
        y_heart = (
            13 * torch.cos(t_heart)
            - 5 * torch.cos(2 * t_heart)
            - 2 * torch.cos(3 * t_heart)
            - torch.cos(4 * t_heart)
        )
        x_1 = torch.stack([x_heart, y_heart], dim=1) * 0.1

        print(f"âœ… 2Dæ•°æ®ç”Ÿæˆå®Œæˆ: {num_points} ä¸ªç‚¹")

        # å¯è§†åŒ–è½¨è¿¹
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        time_points = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]

        for i, t_val in enumerate(time_points):
            ax = axes[i // 3, i % 3]

            t_tensor = torch.full((num_points,), t_val)
            x_t = flow.sample_trajectory(x_0, x_1, t_tensor)

            ax.scatter(x_t[:, 0].numpy(), x_t[:, 1].numpy(), alpha=0.6, s=20)
            ax.set_title(f"t = {t_val:.1f}")
            ax.set_aspect("equal")
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig("flow_matching_trajectory.png", dpi=150, bbox_inches="tight")
        print("âœ… è½¨è¿¹å¯è§†åŒ–ä¿å­˜åˆ°: flow_matching_trajectory.png")

    except ImportError:
        print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–ç¤ºä¾‹")


def main():
    """ä¸»å‡½æ•°."""
    print("ğŸŒŸ AllFlow - Flow Matchingç®—æ³•æ¼”ç¤º")
    print("https://github.com/your-username/allflow")
    print()

    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(42)

    try:
        # åŸºç¡€ç¤ºä¾‹
        simple_model_example()

        # è®­ç»ƒç¤ºä¾‹
        training_example()

        # å¯è§†åŒ–ç¤ºä¾‹
        visualization_example()

        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ“š æ›´å¤šä¿¡æ¯:")
        print("   - æ–‡æ¡£: docs/")
        print("   - æµ‹è¯•: pytest tests/")
        print("   - æ•™ç¨‹: notebooks/")

    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
