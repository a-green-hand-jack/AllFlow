"""AllFlow: é«˜æ•ˆçš„Flow Matchingç®—æ³•åº“

AllFlowæ˜¯ä¸€ä¸ªä¸“æ³¨äºFlow Matchingæ ¸å¿ƒç®—æ³•çš„PyTorchåº“ï¼Œæä¾›é«˜æ•ˆã€å¯æ‰©å±•çš„
Flow Matchingå˜ä½“å®ç°ã€‚æœ¬æ¨¡å—å¯¼å‡ºäº†åº“çš„å…¬å…±APIï¼ŒåŒ…æ‹¬æ‰€æœ‰ç®—æ³•ç±»å’Œå·¥å…·å‡½æ•°ã€‚

ä¸»è¦ç‰¹è‰²ï¼š
- é›¶Pythonå¾ªç¯ï¼Œçº¯å¼ é‡æ“ä½œå®ç°
- ç»Ÿä¸€çš„ç®—æ³•æ¥å£è®¾è®¡
- å®Œæ•´çš„Flow Matchingå˜ä½“è¦†ç›–
- é«˜æ€§èƒ½GPUä¼˜åŒ–

Example:
    åŸºæœ¬ä½¿ç”¨æ–¹å¼ï¼š
    
    >>> import torch
    >>> from allflow import FlowMatching
    >>> 
    >>> flow = FlowMatching(device='cuda')
    >>> x_0 = torch.randn(32, 64, device='cuda')
    >>> x_1 = torch.randn(32, 64, device='cuda')
    >>> t = torch.rand(32, device='cuda')
    >>> 
    >>> velocity = flow.compute_vector_field(x_0, x_1, t)
    >>> loss = flow.compute_loss(x_0, x_1)

Author: AllFlow Contributors
License: MIT
"""

from typing import Any

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "0.1.0"
__author__ = "AllFlow Contributors"

# æ ¸å¿ƒç®—æ³•ç±» - å°†åœ¨å®ç°åå¯¼å…¥
# from .algorithms import (
#     FlowMatching,
#     MeanFlow,
#     ConditionalFlowMatching,
#     RectifiedFlow,
#     OptimalTransportFlow,
# )

# ODEæ±‚è§£å™¨ - å°†åœ¨å®ç°åå¯¼å…¥
# from .solvers import (
#     EulerSolver,
#     HeunSolver,
#     AdaptiveSolver,
# )

# å·¥å…·å‡½æ•° - å°†åœ¨å®ç°åå¯¼å…¥
# from .utils import (
#     validate_tensor_shapes,
#     compute_flow_straightness,
# )

# å…¬å…±APIåˆ—è¡¨ - å®šä¹‰å“ªäº›ç¬¦å·å¯ä»¥è¢«å¤–éƒ¨å¯¼å…¥
__all__ = [
    # ç‰ˆæœ¬ä¿¡æ¯
    "__version__",
    "__author__",
    
    # æ ¸å¿ƒç®—æ³•ç±» (å°†åœ¨å®ç°åå–æ¶ˆæ³¨é‡Š)
    # "FlowMatching",
    # "MeanFlow", 
    # "ConditionalFlowMatching",
    # "RectifiedFlow",
    # "OptimalTransportFlow",
    
    # ODEæ±‚è§£å™¨ (å°†åœ¨å®ç°åå–æ¶ˆæ³¨é‡Š)
    # "EulerSolver",
    # "HeunSolver",
    # "AdaptiveSolver",
    
    # å·¥å…·å‡½æ•° (å°†åœ¨å®ç°åå–æ¶ˆæ³¨é‡Š)
    # "validate_tensor_shapes",
    # "compute_flow_straightness",
]


def _check_dependencies() -> None:
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–å¹¶æ¨èæœ€ä¼˜è®¡ç®—åç«¯."""
    try:
        import torch
        
        # æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§å¹¶ç»™å‡ºå»ºè®®
        available_devices = []
        performance_info = []
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            available_devices.append(f"CUDA (GPU: {gpu_count}ä¸ª)")
            performance_info.append("âœ… CUDA GPUå¯ç”¨ï¼Œå°†è·å¾—æœ€ä½³æ€§èƒ½")
        
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            available_devices.append("MPS (Apple Silicon)")
            performance_info.append("âœ… Apple Silicon MPSå¯ç”¨ï¼Œé’ˆå¯¹Mç³»åˆ—èŠ¯ç‰‡ä¼˜åŒ–")
        
        available_devices.append("CPU")
        
        if len(available_devices) == 1:  # åªæœ‰CPU
            import warnings
            warnings.warn(
                "âš ï¸  åªæœ‰CPUåç«¯å¯ç”¨ï¼Œæ€§èƒ½å¯èƒ½å—é™ã€‚\n"
                "å»ºè®®ï¼š\n"
                "â€¢ Linux: å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch\n"
                "â€¢ Mac: ç¡®ä¿ä½¿ç”¨æ”¯æŒMPSçš„PyTorch 2.0+",
                UserWarning
            )
        else:
            # æœ‰GPUæˆ–MPSåŠ é€Ÿ
            import logging
            logging.info(f"ğŸš€ AllFlowå·²æ£€æµ‹åˆ°åŠ é€Ÿè®¡ç®—åç«¯: {', '.join(available_devices)}")
            for info in performance_info:
                logging.info(info)
                
    except ImportError:
        raise ImportError(
            "AllFlowéœ€è¦PyTorch>=2.0.0ã€‚è¯·æ ¹æ®æ‚¨çš„å¹³å°å®‰è£…ï¼š\n\n"
            "ğŸ“± Apple Silicon Mac:\n"
            "   pip install torch>=2.0.0\n\n"
            "ğŸ§ Linux with CUDA:\n"
            "   pip install torch>=2.0.0 --index-url https://download.pytorch.org/whl/cu118\n\n"
            "ğŸ’» CPU only:\n"
            "   pip install torch>=2.0.0 --index-url https://download.pytorch.org/whl/cpu"
        )


# åœ¨å¯¼å…¥æ—¶æ£€æŸ¥ä¾èµ–
_check_dependencies() 